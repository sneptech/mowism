# Architecture Research: tmux Multi-Agent Execution

**Domain:** tmux-based multi-agent orchestration for existing Mowism CLI
**Researched:** 2026-02-25
**Confidence:** HIGH (verified against Claude Code CLI v2.1.53 --help, tmux 3.6a local install, existing codebase analysis, community patterns)
**Purpose:** Architecture decisions for integrating tmux multi-agent execution into Mowism
**Supersedes:** v1.2-ARCHITECTURE.md for execution mode sections only
**Updated:** 2026-02-25 (cross-check corrections from parallel v1.3-STACK.md research)

## Corrections from Parallel Research Cross-Check

The v1.3-STACK.md researcher identified four corrections to this architecture document. These corrections take precedence over the patterns in the body sections below:

1. **CLAUDECODE=1 env var blocker:** Claude Code sets `CLAUDECODE=1` in its process tree. Spawned `claude` processes inherit this and refuse to start. All `tmux split-window` commands MUST include `-e CLAUDECODE=""` to override. See v1.3-STACK.md for details.

2. **send-keys race condition:** The `send-keys` + `sleep 2` pattern in the Worker Spawning section causes a known race condition (Claude Code issue #23513). Use `split-window "command"` to pass the shell command as the pane's initial process instead.

3. **Permission mode default:** `--dangerously-skip-permissions` should NOT be the default. Use `--permission-mode default` or `--permission-mode acceptEdits`. Let users explicitly opt into dangerous mode via Mowism config.

4. **Workers must be interactive, not headless:** The initial `-p` (headless) recommendation is wrong for full-lifecycle workers. Workers need interactive sessions for multi-step execution and discuss-phase user interaction. The document's later correction (line 180-182) is correct.

**Corrected spawn pattern (preferred over patterns in body sections):**

```bash
# CORRECT: command as split-window argument, env override, interactive mode
tmux split-window -t "${session}" -h -e CLAUDECODE="" \
  "cd ${worktree_path} && claude --session-id mow-phase-${phase} \
   --append-system-prompt '$(cat /tmp/mow-phase-${phase}-prompt.txt)'"
```

## Executive Summary

tmux multi-agent execution replaces Claude Code's experimental Agent Teams as the primary mechanism for parallel phase execution. Instead of relying on the unstable `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1` API with its known limitations (no session resume, no nested teams, one team per session, slow shutdown, tools unavailable in subagent sessions), the orchestrator spawns `claude` CLI processes in tmux panes, each operating in its own git worktree. The orchestrator itself is a Node.js process (in mow-tools.cjs), not a Claude agent -- this eliminates the 200k context window exhaustion problem that plagues the current coordinator model.

The key architectural insight: **the orchestrator does not need to be an LLM.** DAG resolution, worktree management, tmux session control, file-based completion detection, and merge coordination are all deterministic operations that Node.js handles better than a Claude agent. The orchestrator needs intelligence only for presenting results and handling errors -- which it delegates to the user.

## System Overview

```
User Terminal
    |
    v
+--[mow-tools.cjs tmux orchestrate]-----------------------------+
|                                                                 |
|  DAG Analyzer --> Wave Grouper --> Spawner --> Monitor --> Merge |
|      |               |               |           |          |   |
|  ROADMAP.md    Ready phases    tmux panes   fs.watch    git     |
|                                    |        STATUS.md   merge   |
+-------|----------------------------|------------|-----------|----+
        |                            |            |           |
        v                            v            v           v
  .planning/               tmux session      .planning/    main
  ROADMAP.md              "mow-{project}"    phases/       branch
                           /    |    \       NN-STATUS.md
                          /     |     \
                    +----+  +----+  +----+
                    |pane|  |pane|  |pane|
                    | 0  |  | 1  |  | 2  |
                    +----+  +----+  +----+
                      |       |       |
                   claude   claude   claude
                   interactive sessions
                   in worktrees
                   phase-7 phase-8 phase-9
```

### Component Responsibilities

| Component | Responsibility | Location | New/Modified |
|-----------|----------------|----------|--------------|
| **tmux orchestrator** | Session/pane lifecycle, spawn, monitor, merge | `mow-tools.cjs` new `tmux` command group | NEW |
| **DAG analyzer** | Phase dependency resolution, wave grouping | `mow-tools.cjs` existing `analyzeDagInternal()` | EXISTING (no change) |
| **Worktree manager** | Create/merge/clean worktrees | `mow-tools.cjs` existing `worktree` commands | EXISTING (minor: add tmux-aware creation) |
| **File watcher** | Detect STATUS.md changes for completion | `mow-tools.cjs` new watcher in tmux orchestrator | NEW |
| **Worker process** | Run interactive claude in tmux pane with phase prompt | spawned by tmux orchestrator via `tmux split-window "command"` | NEW |
| **Dashboard renderer** | Show multi-phase progress | `mow-tools.cjs` existing `dashboard` commands | MODIFIED (add tmux-specific rendering) |
| **Workflow files** | Define orchestration logic Claude reads | `workflows/auto.md`, `commands/mow/auto.md` | MODIFIED (add tmux mode branch) |

## Architecture Decision: Orchestrator is Node.js, Not Claude

### Why the orchestrator must NOT be a Claude agent

The current architecture (`mow-team-lead.md`) has a fundamental flaw: the orchestrator is a Claude Code agent with a 200k context window. With N phase workers each sending milestone messages plus automatic idle notifications, the orchestrator's context fills proportionally. After 30+ minutes of multi-phase execution, the orchestrator loses track of earlier decisions due to context compression.

Additionally, Agent Teams tools (TaskCreate, TaskUpdate, SendMessage, etc.) are only available in top-level interactive sessions -- not in Task()-spawned subagents. This means the team lead must be the root session, and there is no way to test or debug the coordination flow programmatically.

**tmux orchestration eliminates both problems:**

| Concern | Agent Teams (current) | tmux orchestrator (proposed) |
|---------|----------------------|------------------------------|
| Context window | 200k, fills with N workers x messages | Unlimited (Node.js, no LLM) |
| State tracking | In-context (lossy compression) | On disk (STATE.md, STATUS.md) |
| Tool availability | Only in top-level session | N/A (uses shell commands) |
| Session resume | NOT supported (documented limitation) | Re-read disk state, re-attach tmux |
| Error handling | Claude interprets errors | Node.js deterministic error handling |
| Cost | ~800k tokens for 5-person team | Zero orchestrator tokens (only workers cost) |
| Startup | Slow (Claude processes prompt) | Instant (Node.js) |
| Debugging | Cannot step through | Standard Node.js debugging |

### What the orchestrator does (deterministic, no LLM needed)

1. Parse DAG from ROADMAP.md (existing `analyzeDagInternal`)
2. Group phases into waves (existing `topoGenerations`)
3. Create worktrees (existing `cmdWorktreeCreateNative`)
4. Create tmux session with panes
5. Spawn interactive `claude` in each pane with phase-specific prompt
6. Watch STATUS.md files for completion signals
7. Merge completed worktrees (existing `cmdWorktreeMerge`)
8. Spawn next wave when current wave completes
9. Report results to user

### What workers do (needs LLM)

Each worker is a standalone interactive `claude` process running the full lifecycle: discuss -> research -> plan -> execute -> refine. Workers write STATUS.md to signal progress and completion. Workers do NOT need Agent Teams tools -- they operate independently.

## Worker Spawning Mechanism

### Primary: Interactive `claude` via `tmux split-window`

```bash
# Create tmux session (if not inside tmux already)
tmux new-session -d -s "mow-${project}" -x 200 -y 50

# For each ready phase, create a pane with claude as the initial command
# NOTE: -e CLAUDECODE="" overrides inherited env var that blocks nested claude
tmux split-window -t "mow-${project}" -h -e CLAUDECODE="" \
  "cd ${worktree_path} && claude --session-id mow-phase-${phase} \
   --append-system-prompt '$(cat /tmp/mow-phase-${phase}-prompt.txt)'"
```

### Why interactive mode (not headless `-p`)

1. **Multi-step lifecycle** -- the full lifecycle (discuss -> research -> plan -> execute -> refine) requires multiple turns and tool calls. `-p` exits after one response.
2. **Discuss-phase user interaction** -- discuss is a hard constraint requiring user input. Interactive mode handles this naturally (user attaches to tmux pane).
3. **Direct user access** -- users can attach to any tmux pane and interact with the worker directly (approve permissions, give feedback, adjust approach). This is the fundamental value proposition over Agent Teams subprocess mode.
4. **tmux provides the PTY** -- interactive `claude` needs a PTY, which tmux provides natively.

### Why `split-window "command"` (not `split-window` + `send-keys`)

The `send-keys` pattern has a documented race condition (Claude Code issue #23513): when creating a pane and immediately using `send-keys`, the shell may not be initialized yet. Passing the command directly as an argument to `split-window` is synchronous and avoids the race.

### Why `-e CLAUDECODE=""` is required

Claude Code sets `CLAUDECODE=1` in its process tree. Any `claude` process spawned from within Claude Code inherits this variable and refuses to start. The `-e CLAUDECODE=""` flag on `split-window` overrides the inherited environment variable for the new pane.

### Alternative considered: `claude --worktree --tmux`

Claude Code v2.1.53 supports `claude --worktree [name] --tmux` which creates a worktree and tmux session natively. However:

- **Conflicts with Mowism session management** -- `--tmux` creates its OWN tmux session, conflicting with Mowism's session
- **No prompt injection** -- you cannot pass an initial prompt with `--worktree --tmux` (it opens a blank interactive session)
- **No session ID control** -- the session ID is auto-generated
- **Bypasses Mowism worktree hooks** -- Mowism has mature worktree setup (manifest, .planning/ copy, STATUS.md init)

**Verdict:** Mowism creates its own tmux session and panes. Workers are spawned as `claude --session-id ... --append-system-prompt ...` without `--tmux`.

### Worker prompt construction

The orchestrator writes a temporary prompt file per phase:

```
/tmp/mow-phase-${phase}-prompt.txt
```

Contents:

```
Read and follow ~/.claude/agents/mow-phase-worker.md

Phase: ${phase_number}
Phase name: ${phase_name}
Working directory: ${worktree_path}
Phase directory: ${phase_dir}

Run the full lifecycle: discuss -> research -> plan -> execute -> refine.
Write STATUS.md progress using: node ~/.claude/mowism/bin/mow-tools.cjs status write ${phase_number}
When complete, write "phase_complete" to STATUS.md status field.

Stage gates: ${stage_gates_config}
Auto-advance: true
```

### Discuss-phase special handling

The discuss-phase requires user input (hard constraint). In tmux mode:

1. Worker detects it needs user input for discuss
2. Worker writes `status: awaiting_input` and `input_type: discuss` to STATUS.md
3. Orchestrator detects this via file watcher
4. Orchestrator prints notification: "Phase ${N} needs user input. Attach: tmux attach -t mow-${project}"
5. User attaches to the tmux pane, provides input
6. Worker continues, writes `status: executing` to STATUS.md
7. Orchestrator detects the status change and continues monitoring

Because workers are interactive sessions, discuss-phase works naturally -- the user simply attaches to the pane and interacts with the claude session.

## Completion Detection: fs.watch on STATUS.md

### Why file watching, not polling or tmux hooks

| Method | Pros | Cons |
|--------|------|------|
| **fs.watch (Node.js native)** | Event-driven, zero CPU when idle, cross-platform, no dependencies | Unreliable on some filesystems (NFS), may miss rapid changes |
| **inotifywait** | Linux-native, reliable | External dependency, not installed by default, not cross-platform |
| **Polling (setInterval + fs.readFile)** | 100% reliable, simple | CPU cost with many files, latency = poll interval |
| **tmux hooks (pane-exited)** | Detects pane death | Only fires on exit, not on status changes |
| **tmux capture-pane polling** | Can read terminal output | Fragile (depends on output format), high overhead |

**Recommendation:** Use **fs.watch with polling fallback**. Node.js `fs.watch` uses inotify on Linux, which is efficient. Add a polling fallback (every 5 seconds) for reliability -- if fs.watch misses an event, polling catches it within 5 seconds.

```javascript
// Pseudocode for the watcher
function watchPhaseStatus(phaseDir, phaseNum, callback) {
  const statusPath = path.join(phaseDir, 'STATUS.md');

  // Primary: fs.watch (inotify on Linux)
  const watcher = fs.watch(statusPath, { persistent: true }, (eventType) => {
    if (eventType === 'change') {
      const status = parseStatusFile(statusPath);
      callback(phaseNum, status);
    }
  });

  // Fallback: poll every 5 seconds
  let lastMtime = 0;
  const pollInterval = setInterval(() => {
    try {
      const stat = fs.statSync(statusPath);
      if (stat.mtimeMs > lastMtime) {
        lastMtime = stat.mtimeMs;
        const status = parseStatusFile(statusPath);
        callback(phaseNum, status);
      }
    } catch {}
  }, 5000);

  return { watcher, pollInterval };
}
```

### STATUS.md as the coordination protocol

Workers already write STATUS.md via `mow-tools.cjs status write`. The orchestrator watches for specific status values:

| Status Value | Meaning | Orchestrator Action |
|-------------|---------|---------------------|
| `discussing` | Worker in discuss stage | Show "awaiting input" if no progress for 30s |
| `awaiting_input` | Worker blocked on user input | Notify user with tmux pane reference |
| `researching` | Worker in research stage | Update dashboard |
| `planning` | Worker in plan stage | Update dashboard |
| `executing` | Worker executing plans | Update dashboard |
| `refining` | Worker in refine stage | Update dashboard |
| `complete` | Phase finished | Trigger merge + next wave |
| `error` | Worker hit an error | Notify user, pause cascade |
| `cancelled` | Worker was cancelled | Clean up, skip downstream |

### Completion signal parsing

```javascript
function parseStatusFile(statusPath) {
  const content = fs.readFileSync(statusPath, 'utf-8');
  // Parse the YAML-like frontmatter or markdown structure
  const statusMatch = content.match(/status:\s*(\w+)/);
  const plansMatch = content.match(/plans_completed:\s*(\d+)/);
  const totalMatch = content.match(/plans_total:\s*(\d+)/);
  return {
    status: statusMatch ? statusMatch[1] : 'unknown',
    plansCompleted: plansMatch ? parseInt(plansMatch[1]) : 0,
    plansTotal: totalMatch ? parseInt(totalMatch[1]) : 0,
  };
}
```

## Where tmux Management Code Lives

### New `tmux` subcommand group in mow-tools.cjs

Add a new top-level command group alongside existing `worktree`, `state`, `dashboard`, etc.

```
mow-tools.cjs tmux orchestrate [--phases N,M,...] [--all]
    Full orchestration: DAG -> worktrees -> tmux -> spawn -> monitor -> merge

mow-tools.cjs tmux spawn --phase N --session SESSION --pane PANE
    Spawn a single worker in a tmux pane (used internally)

mow-tools.cjs tmux status [--session SESSION]
    Show status of all tmux workers (reads STATUS.md files)

mow-tools.cjs tmux attach --phase N
    Attach to a specific phase's tmux pane

mow-tools.cjs tmux kill [--phase N | --all]
    Kill a specific worker or all workers

mow-tools.cjs tmux resume [--session SESSION]
    Re-attach to existing session, re-read status, continue
```

### Why in mow-tools.cjs, not a separate script

1. **Access to existing infrastructure** -- DAG analysis, worktree management, STATUS.md parsing, manifest, config are all in mow-tools.cjs
2. **Single dependency** -- users already have Node.js (required for mow-tools.cjs)
3. **Consistent CLI interface** -- `mow-tools.cjs tmux orchestrate` follows the existing pattern
4. **MAINT-01 alignment** -- when mow-tools.cjs is eventually split into modules, the tmux module splits cleanly

### Estimated code footprint

| Function | Lines | Complexity |
|----------|-------|------------|
| `cmdTmuxOrchestrate` (main loop) | ~200 | Medium (DAG + loop + watchers) |
| `cmdTmuxSpawn` (single worker spawn) | ~80 | Low (tmux commands + prompt file) |
| `cmdTmuxStatus` | ~40 | Low (read STATUS.md files) |
| `cmdTmuxKill` | ~30 | Low (tmux kill-pane) |
| `cmdTmuxResume` | ~60 | Medium (re-read state, re-attach) |
| `watchPhaseStatus` (file watcher) | ~50 | Low |
| `tmuxSessionManager` (session/pane CRUD) | ~100 | Medium (tmux command wrapper) |
| CLI routing | ~30 | Low |
| **Total** | **~590** | |

This is ~7% of the current 8,700 LOC -- reasonable for a new capability.

## Orchestration Flow (Detailed)

### Step 1: Initialization

```
1. User runs /mow:auto (which calls mow-tools.cjs tmux orchestrate)
   OR
   User runs: node ~/.claude/mowism/bin/mow-tools.cjs tmux orchestrate

2. Orchestrator reads DAG:
   dag = analyzeDagInternal(cwd)

3. Orchestrator presents plan to user:
   "Phases 7, 8, 9 are ready (Wave 1). Phases 10, 11 are blocked (Wave 2)."
   "Proceed? [y/n]"

4. User confirms (or orchestrator auto-proceeds if invoked from /mow:auto)
```

### Step 2: Worktree Creation + tmux Session

```
5. Detect tmux context:
   If $TMUX is set: create new-window in existing session
   If $TMUX is unset: create new-session

6. For each ready phase in Wave 1:
   a. Create worktree: mow-tools.cjs worktree create-native --name phase-${NN}
   b. Create tmux pane with claude as initial command:
      tmux split-window -t "${session}" -h -e CLAUDECODE="" \
        "cd ${worktree_path} && claude --session-id mow-phase-${NN} \
         --append-system-prompt '$(cat /tmp/mow-phase-${NN}-prompt.txt)'"
   c. Apply layout: tmux select-layout -t "${session}" tiled

7. Start file watchers on each worktree's STATUS.md
```

### Step 3: Monitoring

```
8. Event loop (Node.js):
   - fs.watch triggers on STATUS.md change
   - Parse new status
   - Update dashboard (print to orchestrator's terminal)
   - If status == "complete": mark phase done, check if wave is done
   - If status == "awaiting_input": notify user with pane reference
   - If status == "error": handle error (see error handling)

9. When all phases in current wave are complete:
   a. Merge each phase branch (serialized, not concurrent):
      mow-tools.cjs worktree merge ${phase}
   b. Create worktrees for next wave (from post-merge main)
   c. Spawn workers for next wave
   d. Repeat from step 7
```

### Step 4: Completion

```
10. When all waves complete:
    a. Kill tmux session (or leave for user inspection)
    b. Update STATE.md with completion
    c. Print summary report
    d. Clean up temp files
```

## Data Flow Diagram

```
                         /mow:auto
                             |
                             v
            +---[Workflow: auto.md]---+
            |  Detect tmux available  |
            |  Call tmux orchestrate  |
            +-----------+------------+
                        |
                        v
            +---[mow-tools.cjs]------+
            |  tmux orchestrate      |
            |                        |
            |  1. analyzeDagInternal |----> ROADMAP.md
            |  2. topoGenerations   |
            |  3. for ready phases:  |
            |     a. worktree create |----> .claude/worktrees/phase-NN/
            |     b. split-window    |----> tmux session "mow-{project}"
            |        "claude ..."    |      (with -e CLAUDECODE="")
            |  4. fs.watch loop      |<---- STATUS.md (per phase)
            |  5. on complete:       |
            |     a. worktree merge  |----> git merge phase-NN -> main
            |     b. spawn next wave |
            |  6. final report       |
            +------------------------+
                        |
                        v
                  User terminal
                  (orchestrator output)
```

### File-Based Coordination Protocol

```
Orchestrator (Node.js)          Worker (Claude in tmux pane)
        |                                   |
        |--- create worktree ------------->|
        |--- create STATUS.md ------------>|
        |--- spawn claude (split-window)-->|
        |                                   |
        |                          [discuss phase]
        |                                   |
        |<-- STATUS.md: awaiting_input -----|
        |--- notify user ----------------->|
        |                          [user provides input]
        |<-- STATUS.md: researching --------|
        |                                   |
        |                          [research, plan, execute]
        |                                   |
        |<-- STATUS.md: complete -----------|
        |--- merge worktree                 |
        |--- spawn next wave                |
```

## Graceful Fallback: Same Workflow, Different Spawn

### Detection logic

```javascript
function detectExecutionMode() {
  // 1. Check if tmux is available
  try {
    execSync('tmux -V', { stdio: 'pipe' });
  } catch {
    return 'sequential';  // No tmux -> sequential fallback
  }

  // 2. Check if user opted out
  const config = readConfig(cwd);
  if (config.execution_mode === 'sequential') {
    return 'sequential';
  }

  // 3. Check if Agent Teams is available (legacy mode)
  if (config.execution_mode === 'agent-teams') {
    const at = checkAgentTeams();
    if (at.enabled) return 'agent-teams';
  }

  // 4. Default: tmux if available
  return 'tmux';
}
```

### Three execution modes

| Mode | Trigger | How workers spawn | Orchestrator |
|------|---------|-------------------|-------------|
| **tmux** (new default) | tmux installed + not opted out | `claude` in tmux panes | `mow-tools.cjs tmux orchestrate` (Node.js) |
| **agent-teams** (legacy) | `config.execution_mode == 'agent-teams'` + AT enabled | `Task()` with `team_name` | `mow-team-lead.md` (Claude agent) |
| **sequential** (fallback) | No tmux, no AT, or explicit opt-out | Inline in current session | `/mow:auto` sequential chain |

### How `/mow:auto` triggers the right mode

The `auto.md` workflow currently has Step 4 (`check_agent_teams`) that branches between `team_lead_delegation` and `sequential_fallback`. Add a new branch:

```
Step 4: Check Execution Mode

Run: node ~/.claude/mowism/bin/mow-tools.cjs detect-execution-mode --raw
Parse: { mode: "tmux" | "agent-teams" | "sequential" }

If "tmux":
  Run: node ~/.claude/mowism/bin/mow-tools.cjs tmux orchestrate --all
  (This is a blocking call -- the Node.js orchestrator runs the full pipeline)
  Parse exit code and stdout for results.

If "agent-teams":
  (Existing team_lead_delegation flow -- unchanged)

If "sequential":
  (Existing sequential_fallback flow -- unchanged)
```

### How `/mow:execute-phase` triggers tmux mode

For single-phase execution with multiple plans:

```
Step: Check if tmux parallel is appropriate

If plan_count >= 3 AND tmux available AND parallelization enabled:
  Run: node ~/.claude/mowism/bin/mow-tools.cjs tmux orchestrate --phases ${PHASE}
  (Orchestrator creates panes for each plan executor within the phase)

Otherwise:
  (Existing wave-based sequential execution)
```

## Integration Points with Existing Code

### Modified Components

| Component | What Changes | Why |
|-----------|-------------|-----|
| `workflows/auto.md` | Add tmux mode branch in Step 4 | Route to tmux orchestrator when available |
| `commands/mow/auto.md` | No change needed | Already delegates to auto.md workflow |
| `mow-tools.cjs` CLI router | Add `tmux` command group | Route tmux subcommands |
| `cmdWorktreeCreateNative` | Minor: accept `--tmux-session` param for pane tracking | Track which tmux pane owns which worktree |
| `dashboard render` | Add tmux-aware rendering (multi-pane status) | Show which pane each phase is in |
| `checkAgentTeams` | Rename to `detectExecutionMode`, add tmux check | Unified mode detection |

### New Components

| Component | Purpose | Integration Point |
|-----------|---------|-------------------|
| `cmdTmuxOrchestrate` | Main orchestration loop | Called from auto.md workflow |
| `cmdTmuxSpawn` | Spawn single worker | Called by orchestrate |
| `cmdTmuxStatus` | Query worker statuses | Called by dashboard, user |
| `cmdTmuxKill` | Kill workers | Called by close-shop, user |
| `cmdTmuxResume` | Resume interrupted session | Called by resume-work |
| `watchPhaseStatus` | File watcher for STATUS.md | Used by orchestrate loop |
| `tmuxSessionManager` | Thin wrapper around tmux CLI | Used by all tmux commands |
| `detect-execution-mode` | Unified mode detection | Replaces checkAgentTeams in workflows |

### Unchanged Components

| Component | Why No Change |
|-----------|---------------|
| `mow-phase-worker.md` | Workers are autonomous -- same lifecycle regardless of spawn mechanism |
| `mow-executor.md` | Executors are leaf workers -- no coordination awareness |
| `mow-worktree-create.sh` hook | Still handles worktree setup correctly |
| `mow-worktree-remove.sh` hook | Still handles cleanup |
| STATUS.md protocol | Already exists, workers already write it |
| `cmdWorktreeMerge` | Already handles git merge correctly |
| `analyzeDagInternal` | Already produces the DAG structure needed |

## tmux Session Layout

### Naming Convention

```
Session:  mow-${project-name}
Window:   wave-${N} (one window per wave)
Panes:    phase-${NN} (one pane per phase in the wave)
```

### Pane Layout Strategy

For 1-3 phases per wave: horizontal split (each pane gets full width)
For 4-6 phases: tiled layout (2x2, 2x3)
For 7+ phases: tiled with smaller panes (user can zoom with Ctrl-b z)

```javascript
function layoutPanes(paneCount) {
  if (paneCount <= 3) return 'even-horizontal';
  if (paneCount <= 6) return 'tiled';
  return 'tiled';  // tmux handles >6 fine with tiled
}
```

### Orchestrator pane

The orchestrator does NOT run in a tmux pane. It runs in the user's current terminal. tmux panes are for workers only. This means:

- User sees orchestrator output (progress, notifications) in their terminal
- Workers are in background tmux panes
- User can `tmux attach -t mow-${project}` to see workers
- User can `tmux select-pane -t mow-${project}:0.${N}` to interact with a specific worker

## Error Handling

### Worker crash detection

```javascript
// Detect pane death via tmux list-panes
function checkPaneAlive(session, paneIndex) {
  try {
    const result = execSync(
      `tmux list-panes -t "${session}" -F "#{pane_index} #{pane_dead}"`,
      { encoding: 'utf-8' }
    );
    const lines = result.trim().split('\n');
    for (const line of lines) {
      const [idx, dead] = line.split(' ');
      if (parseInt(idx) === paneIndex) return dead !== '1';
    }
    return false;
  } catch {
    return false;
  }
}
```

### Circuit breaker

Same logic as current `mow-team-lead.md`:

```javascript
let failureCount = 0;
const threshold = config.multi_phase?.circuit_breaker_threshold || 2;

function onPhaseError(phase) {
  failureCount++;
  if (failureCount >= threshold) {
    console.log(`Circuit breaker tripped: ${failureCount} failures. Killing all workers.`);
    killAllWorkers();
    return;
  }
  // Independent phases keep running
  const blocked = getBlockedPhases(phase, dag);
  console.log(`Phase ${phase} failed. Blocks: ${blocked.join(', ')}. Independent phases continue.`);
}
```

### Session resume

If the orchestrator crashes or the user interrupts:

1. tmux session persists (that is tmux's superpower)
2. Workers in panes continue running
3. User runs `mow-tools.cjs tmux resume`:
   a. Read manifest to discover active worktrees
   b. Re-read STATUS.md for each phase to get current status
   c. Re-attach watchers
   d. Continue monitoring from current state

## Anti-Patterns

### Anti-Pattern 1: Orchestrator as Claude agent

**What people do:** Use a Claude agent (like mow-team-lead.md) to coordinate tmux sessions
**Why it's wrong:** The orchestrator's context window fills up, it costs tokens for deterministic operations, and it cannot be debugged
**Do this instead:** Use Node.js for orchestration. Only use Claude for the workers that need intelligence.

### Anti-Pattern 2: Parsing tmux pane output for coordination

**What people do:** Use `tmux capture-pane` to read worker output and detect completion
**Why it's wrong:** Fragile (depends on exact output format), expensive (polling), unreliable (output may be scrolled off)
**Do this instead:** Use file-based coordination (STATUS.md). Workers write structured state to files, orchestrator watches files.

### Anti-Pattern 3: Using `claude -p` for full-lifecycle workers

**What people do:** Run `claude -p` (headless) and try to handle the full discuss -> execute lifecycle
**Why it's wrong:** `-p` mode exits after one response. The full lifecycle is multi-step and multi-turn. Discuss-phase requires user interaction.
**Do this instead:** Spawn interactive `claude` sessions. The user can attach to tmux panes and interact directly.

### Anti-Pattern 4: Single tmux window for all phases

**What people do:** Split one window into N panes for N phases
**Why it's wrong:** With 6+ phases, each pane is tiny and unreadable. Pane indices become confusing.
**Do this instead:** Use one tmux window per wave. Wave 1 has its own window, Wave 2 has its own window. Cleaner separation, easier navigation.

### Anti-Pattern 5: Using `send-keys` for initial commands

**What people do:** Create a pane with `split-window`, then type the command with `send-keys` + `sleep`
**Why it's wrong:** Race condition between pane creation and shell initialization (Claude Code issue #23513). Commands arrive garbled or are lost.
**Do this instead:** Pass the command as an argument to `split-window "command"`, which tmux executes synchronously.

## Build Order (Dependency-Aware)

Suggested phase structure based on dependencies:

```
Phase 1: tmux Session Management Foundation
  - tmuxSessionManager (create, split-window, list-panes, kill, $TMUX detection)
  - detect-execution-mode (replaces checkAgentTeams)
  - CLI routing for tmux subcommands
  - CLAUDECODE="" environment override
  Depends on: nothing new
  Tests: can create session, spawn echo in pane, kill session

Phase 2: Worker Spawning
  - cmdTmuxSpawn (single worker in pane via split-window "claude ...")
  - Prompt file generation (write to /tmp, pass via --append-system-prompt)
  - Worker -> STATUS.md signaling verification
  Depends on: Phase 1
  Tests: spawn claude in tmux pane, verify STATUS.md written

Phase 3: File-Based Completion Detection
  - watchPhaseStatus (fs.watch + polling fallback)
  - STATUS.md parsing
  - Completion callback
  Depends on: Phase 2 (needs worker to write STATUS.md)
  Tests: mock STATUS.md writes, verify callbacks fire

Phase 4: Full Orchestration Loop
  - cmdTmuxOrchestrate (DAG -> waves -> spawn -> monitor -> merge)
  - Wave boundary handling (serialized merge queue)
  - Error handling + circuit breaker
  - SIGINT handler for graceful shutdown
  Depends on: Phases 1, 2, 3
  Tests: end-to-end with 2-3 mock phases

Phase 5: Workflow Integration
  - Modify auto.md for tmux branch
  - Modify execute-phase.md for tmux parallel plans
  - Add /mow:tmux-status command
  - Resume support (cmdTmuxResume)
  Depends on: Phase 4
  Tests: /mow:auto runs through tmux mode

Phase 6: Polish + Fallback
  - Dashboard integration (tmux-aware rendering)
  - Close-shop integration
  - Agent Teams fallback preservation
  - Sequential fallback verification
  - Pane border theming (per-phase colors)
  Depends on: Phase 5
  Tests: all three modes work correctly
```

## Sources

- Claude Code CLI v2.1.53 `--help` output (local machine, verified 2026-02-25) -- HIGH confidence
- tmux 3.6a (local installation) -- HIGH confidence
- [claude-yolo](https://github.com/claude-yolo/claude-yolo) -- tmux + auto-approve pattern -- MEDIUM confidence
- [Kaushik Gopal: agent forking with tmux](https://kau.sh/blog/agent-forking/) -- MEDIUM confidence
- [Claude Code Multi-Agent tmux Setup](https://medium.com/medialesson/claude-code-multi-agent-tmux-setup-7361b71ff5c4) -- MEDIUM confidence
- [Boris Cherny: claude --worktree --tmux](https://www.threads.com/@boris_cherny/post/DVAAoZ3gYut/) -- MEDIUM confidence
- [Claude Code headless docs](https://code.claude.com/docs/en/headless) -- HIGH confidence
- [Claude Code CLI reference](https://code.claude.com/docs/en/cli-reference) -- HIGH confidence
- [Claude Code Agent Teams docs](https://code.claude.com/docs/en/agent-teams) -- HIGH confidence
- [Agent Teams pane spawning issue #23615](https://github.com/anthropics/claude-code/issues/23615) -- MEDIUM confidence
- [Claude Code send-keys race issue #23513](https://github.com/anthropics/claude-code/issues/23513) -- HIGH confidence
- [Claude Agent SDK CLAUDECODE env var issue #573](https://github.com/anthropics/claude-agent-sdk-python/issues/573) -- HIGH confidence
- Existing Mowism codebase analysis (mow-tools.cjs, agents/, workflows/) -- HIGH confidence
- Existing research: `.planning/research/AGENT-TEAMS-API.md` (2026-02-20) -- HIGH confidence
- Node.js fs.watch documentation -- HIGH confidence

---
*Architecture research for: tmux multi-agent execution integration*
*Researched: 2026-02-25*
*Updated: 2026-02-25 (cross-check corrections from parallel v1.3-STACK.md research)*
